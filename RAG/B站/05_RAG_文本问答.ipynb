{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befac4f2",
   "metadata": {},
   "source": [
    "## 任务6：多路召回+重排序case2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7908eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0832311-f722-4d88-a59b-e89f9466295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('C-MTEB/DuRetrieval')\n",
    "qrels = load_dataset('C-MTEB/DuRetrieval-qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acb6ae6-2c4e-4bf6-b05c-77efddab193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    corpus: Dataset({\n",
       "        features: ['id', 'text'],\n",
       "        num_rows: 100001\n",
       "    })\n",
       "    queries: Dataset({\n",
       "        features: ['id', 'text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d977c6-1d2f-403e-8bf7-548f8a7eeb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['qid', 'pid', 'score'],\n",
       "        num_rows: 9839\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b8932d-1415-4e59-8b7a-4afea15e9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_pd = pd.DataFrame(qrels[\"dev\"])\n",
    "qrels_dict = qrels_pd.groupby(\"qid\")[\"pid\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0820d18-5c28-4aa7-b236-173d2acdd7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel,OkapiBM25Model\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4381543b-8769-42cf-9b4a-1e37022d4bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天 很开心', '明天 也 很开心', 'Python is programming language']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus =[\n",
    "    \"今天 很开心\",\n",
    "    \"明天 也 很开心\",\n",
    "    \"Python is programming language\"\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68990e9-bd97-4ccc-b783-3bfc74f374fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今天', '很开心'],\n",
       " ['明天', '也', '很开心'],\n",
       " ['python', 'is', 'programming', 'language']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_split = [doc.lower().split() for doc in corpus]\n",
    "corpus_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3daf7d2a-0899-4dbd-b701-0df718bc3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 今天\n",
      "1 很开心\n",
      "2 也\n",
      "3 明天\n",
      "4 is\n",
      "5 language\n",
      "6 programming\n",
      "7 python\n"
     ]
    }
   ],
   "source": [
    "dictionary=Dictionary(corpus_split)  ## 这个是将里面的每个value进行了去重，生成词典\n",
    "for key,value in dictionary.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afdbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_model = OkapiBM25Model(dictionary=dictionary) # 相当于给模型喂一本词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19586640-4f54-4d39-a694-1eaf0e750386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6009713220776361), (1, 0.11268212288955677)]\n",
      "[(1, 0.09577980445612325), (2, 0.5108256237659907), (3, 0.5108256237659907)]\n",
      "[(4, 0.44419619457912235), (5, 0.44419619457912235), (6, 0.44419619457912235), (7, 0.44419619457912235)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dictionary.doc2bow：是一个方法，用来将文档表示为词袋的形式（Bag of Words），即将文档中的单词转换成整数索引，并计算它们的词频\n",
    "# map(dictionary.doc2bow,corpus_split)：对corpus_split中的每个文档应用转换成词袋的表示形式\n",
    "# list是将这些词袋表示的文档重新组合成一个列表\n",
    "# bm25_model[...] 这部分代码使用了 Python 中的列表推导式，对 list(map(dictionary.doc2bow, corpus_split)) 中的每个文档应用了 bm25_model，即将文档转换为 Okapi BM25 模型的表示形式。\n",
    "# bm25_model[list(map(dictionary.doc2bow, corpus_split))] 这行代码实际上是将整个语料库（由 corpus_split 表示）转换为 Okapi BM25 模型的表示形式，以便后续用于相似性计算和搜索\n",
    "\n",
    "bm25_corpus = bm25_model[list(map(dictionary.doc2bow,corpus_split))] # 先转换成词袋，再转换成模型的表示形式\n",
    "for i in bm25_corpus:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa680d7f-ad55-4a17-899a-72e9335145f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_corpus 是已经通过 Okapi BM25 模型处理过的语料库，其中每个文档都被表示为一个 Okapi BM25 模型表示形式。\n",
    "# SparseMatrixSimilarity 是 Gensim 库中的类，用于构建一个稀疏矩阵相似性索引器。\n",
    "# num_docs=len(corpus_split) 指定了语料库中文档的数量，这里使用了 len(corpus_split) 来获取文档数量。\n",
    "# num_terms=len(dictionary) 指定了语料库中的唯一词汇数量，这里使用了 len(dictionary) 来获取词汇数量。\n",
    "# normalize_queries=False 表示不对查询进行规范化，即不对查询向量进行归一化处理。\n",
    "# normalize_documents=False 表示不对文档进行规范化，即不对文档向量进行归一化处理。\n",
    "# 因此，整个行代码的含义是在基于 Okapi BM25 模型处理过的语料库上构建一个稀疏矩阵相似性索引器 bm25_index，以便后续用于执行相似性搜索操作。这个索引器可以用于计算查询与文档之间的相似性得分，从而找到与查询最匹配的文档。\n",
    "# 生成了相似性索引器\n",
    "bm25_index = SparseMatrixSimilarity(bm25_corpus,num_docs=len(corpus_split),num_terms=len(dictionary),normalize_queries=False,normalize_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f14150a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60097134 0.         0.        ]\n",
      "['今天', '很开心']\n"
     ]
    }
   ],
   "source": [
    "query = [\"learn\",\"今天\"]\n",
    "tfidf_model=TfidfModel(dictionary=dictionary,smartirs='bnn') # 使用之前的 字典，并bnn指定了对查询进行二进制加权\n",
    "tfidf_query = tfidf_model[dictionary.doc2bow(query)] #将查询词转换成词袋的表示，并进行TF-IDF加权 \n",
    "smiilarities = bm25_index[tfidf_query]  # 用相似性索引器 计算查询文本tfidf_query与语料库中的每个文档的相似性得分\n",
    "print(smiilarities) # 打印出与每个文档的相似性得分\n",
    "best_document=corpus_split[np.argmax(smiilarities)] # 找出相似性得分最大的，并且输出索引，最后查询出词\n",
    "print(best_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbbc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
