{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156264d7-30e1-4c44-97a7-04d12a80eeec",
   "metadata": {},
   "source": [
    "## 任务5：文本多路召回与重排序\n",
    "## YINKA & CONAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f38acf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at infgrad/stella-base-zh-v3-1792d and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## 导入库\n",
    "import json\n",
    "import pdfplumber\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## 加载数据\n",
    "questions = json.load(open(\"../data/Coggle比赛数据/汽车知识问答/questions.json\",encoding=\"utf8\"))\n",
    "pdf = pdfplumber.open(\"../data/Coggle比赛数据/汽车知识问答/初赛训练数据集.pdf\")\n",
    "\n",
    "## 定义分本切分函数\n",
    "def split_text_fixed_size(text,chunk_size): # 拆分文本\n",
    "    return [text[i : i+chunk_size] for i in range( 0 , len(text), chunk_size)]\n",
    "\n",
    "## 切分文本\n",
    "pdf_content=[]\n",
    "for page_idx in range(len(pdf.pages)):\n",
    "\n",
    "    # 把每一页的所有文本提炼出来[]\n",
    "    text = pdf.pages[page_idx].extract_text()\n",
    "   \n",
    "    # 每40句组成一个embedding组\n",
    "    for chunk_text in split_text_fixed_size(text,60):\n",
    "        pdf_content.append({\n",
    "            'page':'page_'+str(page_idx + 1),\n",
    "            'content':chunk_text\n",
    "        })\n",
    "pdf_content[:10]\n",
    "model_names = [\"TencentBAC/Conan-embedding-v1\",\"Classical/Yinka\",\"infgrad/stella-base-zh-v3-1792d\"]\n",
    "for i in range(len(model_names)):\n",
    "    if i==0:\n",
    "        a=\"conan\"\n",
    "    elif i==1:\n",
    "        a=\"yinka\"\n",
    "    else:\n",
    "        a=\"stella\"\n",
    "    ## 加载模型\n",
    "    model = SentenceTransformer(model_names[i],device='cuda')\n",
    "\n",
    "    # 处理句子分词\n",
    "    questions_sentences = [x['question'] for x in questions]\n",
    "\n",
    "    # 之前x[\"content\"]是一页的内容，现在是chunk_size为40的小段话，同时也有这段话的页码，也就是一个页码会对应好几段话\n",
    "    pdf_content_sentences = [x[\"content\"] for x in pdf_content]\n",
    "\n",
    "    # embedding处理\n",
    "    question_embeddings = model.encode(questions_sentences,normalize_embeddings=True)\n",
    "    pdf_embeddings = model.encode(pdf_content_sentences,normalize_embeddings=True)\n",
    "\n",
    "    ## 召回评分\n",
    "    for query_idx, feat in enumerate(question_embeddings):\n",
    "        score = feat @ pdf_embeddings.T\n",
    "        max_score_page_idx = score.argsort()[-3:] # 之前是idx一一对应page，现在是几个idx同一个page，找page方式自然不同\n",
    "        result = [pdf_content[x]['page'] for x in max_score_page_idx]\n",
    "        questions[query_idx]['reference'] = result\n",
    "\n",
    "\n",
    "    ## 保存结果top10\n",
    "    with open(f'../data/Coggle比赛数据/汽车知识问答/submit_{a}_top10.json', 'w', encoding='utf8') as up:\n",
    "        json.dump(questions, up, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de7dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重排序\n",
    "import json\n",
    "yinka = json.load(open(\"../data/Coggle比赛数据/汽车知识问答/submit_yinka_top10.json\",encoding='utf-8'))\n",
    "conan =json.load(open(\"../data/Coggle比赛数据/汽车知识问答/submit_conan_top10.json\",encoding = 'utf8'))\n",
    "stella =json.load(open(\"../data/Coggle比赛数据/汽车知识问答/submit_stella_top10.json\",encoding = 'utf8'))\n",
    "\n",
    "fusion_result = []\n",
    "k=60\n",
    "for q1,q2,q3 in zip(yinka,conan,stella):\n",
    "    fusion_score = {}\n",
    "    for idx,q in enumerate(q2['reference']):\n",
    "        if q not in fusion_score:\n",
    "            fusion_score[q]=1/(idx+k)\n",
    "        else:\n",
    "            fusion_score[q]+=1/(idx+1)\n",
    "    for idx,q in enumerate(q2['reference']):\n",
    "        if q not in fusion_score:\n",
    "            fusion_score[q]=1/(idx+k)\n",
    "        else:\n",
    "            fusion_score[q]+=1/(idx+1) \n",
    "    for idx,q in enumerate(q3['reference']):\n",
    "        if q not in fusion_score:\n",
    "            fusion_score[q]=1/(idx+k)\n",
    "        else:\n",
    "            fusion_score[q]+=1/(idx+1)    \n",
    "    sorted_dict=sorted(fusion_score.items(),key = lambda item:item[1],reverse=True)\n",
    "    q1['reference']=sorted_dict[0][0]\n",
    "    fusion_result.append(q1)\n",
    "\n",
    "with open('../data/Coggle比赛数据/汽车知识问答/submit_fusion_yinka_stella_conan.json', 'w', encoding='utf8') as up:\n",
    "    json.dump(fusion_result, up, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
